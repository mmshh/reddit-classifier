{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, ComplementNB, BernoulliNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jess/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import convert_to_csv, read_train_data, read_test_data\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_comments(comment, result):\n",
    "    classes_name, classes_count = np.unique(comment, return_index=True)\n",
    "    tag = []\n",
    "    \n",
    "    for i in classes_count:\n",
    "        tag.append(result[i])\n",
    "    \n",
    "    return classes_name, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classes_to_integer(tag):\n",
    "    lab = []\n",
    "    classes_name = np.unique(tag)\n",
    "    for i in range(len(tag)):\n",
    "        lab.append(np.where(classes_name == tag[i])[0][0])\n",
    "    lab = np.asarray(lab)\n",
    "    \n",
    "    return classes_name, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datas():\n",
    "    train_data = read_train_data()\n",
    "    test_data = read_test_data()\n",
    "    comment = train_data[0]\n",
    "    result = train_data[1]\n",
    "    \n",
    "    comment_unique, result_unique = unique_comments(comment, result)\n",
    "    classes_name, result_unique_integer = classes_to_integer(result_unique)\n",
    "    \n",
    "    return comment_unique, result_unique_integer, test_data, classes_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_testing():\n",
    "    \n",
    "    comment_unique, result_unique_integer, test_data, classes_name = get_datas()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "     comment_unique, result_unique_integer, test_size=0.33, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, classes_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_multNB(X_train, y_train, X_test, a):\n",
    "    text_clf = Pipeline([\n",
    "         ('vect', CountVectorizer()),\n",
    "         ('tfidf', TfidfTransformer()),\n",
    "         ('clf', MultinomialNB(alpha=a)),\n",
    "    ])\n",
    "    \n",
    "    ovr = OneVsRestClassifier(text_clf)\n",
    "    ovr.fit(X_train, y_train)  \n",
    "    \n",
    "    pred1 = ovr.predict_proba(X_test)\n",
    "    return pred1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_compNB(X_train, y_train, X_test, a):\n",
    "    text_clf2 = Pipeline([\n",
    "         ('vect', CountVectorizer()),\n",
    "         ('tfidf', TfidfTransformer()),\n",
    "         ('clf', ComplementNB(alpha=a)),\n",
    "    ])\n",
    "    \n",
    "    ovr2 = OneVsRestClassifier(text_clf2)\n",
    "    ovr2.fit(X_train, y_train)  \n",
    "    \n",
    "    pred2 = ovr2.predict_proba(X_test)\n",
    "    return pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_sgd(x_t, y_t, x_test, a):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier(loss='log', penalty='elasticnet',alpha=a, random_state=42,\n",
    "                            fit_intercept = False,  tol=0.00001, early_stopping=True, \n",
    "                                         n_iter_no_change=400, max_iter=20)),\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "    \n",
    "    y_pred = sgd.predict_proba(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def score_c(predictions, result):\n",
    "        count = 0\n",
    "        for i in range(len(predictions)):\n",
    "            if(predictions[i] == result[i]):\n",
    "                count += 1\n",
    "        return 100*count/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_testing():\n",
    "    X_train, X_test, y_train, y_test, classes_name = get_data_for_testing()\n",
    "    pred1 = train_predict_multNB(X_train, y_train, X_test, 0.15)\n",
    "    pred2 = train_predict_compNB(X_train, y_train, X_test, 0.24)\n",
    "    pred3 = train_predict_sgd(X_train, y_train, X_test, 0.00001)\n",
    "    \n",
    "    pred = 15*pred1+10*pred2+6*pred4\n",
    "    \n",
    "    p  = [] \n",
    "    for i in range(len(pred)):\n",
    "        p.append(classes_name[np.argmax(pred[i])])\n",
    "        \n",
    "    y  = [] \n",
    "    for i in range(len(y_test)):\n",
    "        y.append(classes_name[y_test[i]])\n",
    "    \n",
    "    return score_c(y, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions():\n",
    "    X_train, y_train, X_test, classes_name = get_datas()\n",
    "    pred1 = train_predict_multNB(X_train, y_train, X_test, 0.15)\n",
    "    pred2 = train_predict_compNB(X_train, y_train, X_test, 0.24)\n",
    "    pred3 = train_predict_sgd(X_train, y_train, X_test, 0.00001)\n",
    "    \n",
    "    pred = 15*pred1+10*pred2+6*pred4\n",
    "    \n",
    "    p  = [] \n",
    "    for i in range(len(pred)):\n",
    "        p.append(classes_name[np.argmax(pred[i])])\n",
    "        \n",
    "    res = []\n",
    "    for i in range(len(p)):\n",
    "        res.append({'Id': i, 'Category': p[i]})\n",
    "        \n",
    "    convert_to_csv(res)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZER TWEET + NUMBERS\n",
    "        resultat_tweet = []\n",
    "\n",
    "        \n",
    "        tknzr = TweetTokenizer()\n",
    "        resultat_tweet_token = (tknzr.tokenize(words.lower()))\n",
    "\n",
    "        final = []\n",
    "        for j in range(len(resultat_tweet_token)):\n",
    "            if(resultat_tweet_token[j].isdigit()):\n",
    "                if(len(resultat_tweet_token[j]) == 4):\n",
    "                    final.append('numerotypeDate')\n",
    "                else:\n",
    "                    final.append('numerotype')\n",
    "            elif(len(resultat_tweet_token[j]) == 1):\n",
    "                if((resultat_tweet_token[j].isalpha() or resultat_tweet_token[j] == \"$\")):\n",
    "                    final.append(resultat_tweet_token[j])\n",
    "            else:\n",
    "                final.append(resultat_tweet_token[j])\n",
    "        return final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
