{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_to_csv, read_train_data, read_test_data\n",
    "train_data = read_train_data()\n",
    "comment = train_data[0]\n",
    "result = train_data[1]\n",
    "test_data = read_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def score_c(predictions, result):\n",
    "        count = 0\n",
    "        for i in range(len(predictions)):\n",
    "            if(predictions[i] == result[i]):\n",
    "                count += 1\n",
    "        return 100*count/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = []\n",
    "classes_name, classes_count = np.unique(result, return_counts=True)\n",
    "for i in range(len(result)):\n",
    "    lab.append(np.where(classes_name == result[i])[0][0])\n",
    "lab = np.asarray(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     comment, lab, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(a, maxIt, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier(loss='hinge', penalty='elasticnet',alpha=a, random_state=42,\n",
    "                            fit_intercept = False,  tol=0.00001, early_stopping=True, \n",
    "                                         n_iter_no_change=400, max_iter=20)),\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred\n",
    "    #print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict2(to, c, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LinearSVC(penalty='l2', loss='hinge', dual=True, tol=to, C=c, \n",
    "                                      multi_class='ovr', fit_intercept=False, intercept_scaling=1, \n",
    "                                      class_weight=w, verbose=0, random_state=None, max_iter=20)),\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict4(to, c, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression(C=1, solver='sag', multi_class='ovr', max_iter=1000))\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "def train_predict5(to, c, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', NearestCentroid())\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def train_predict6(to, c, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', ExtraTreesClassifier(n_estimators='warn', criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None))\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def train_predict7(to, c, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False))\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "def train_predict8(to, c, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', Perceptron(penalty=None, alpha=0.0001, fit_intercept=False, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=True))\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def train_predict9(to, c, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None))\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def train_predict10(to, c, x_t, y_t, x_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None))\n",
    "                   ])\n",
    "    sgd.fit(x_t, y_t)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = sgd.predict(x_test)\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [ 1e-5]\n",
    "maxIt = [ 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for al in alpha:\n",
    "    for maxI in maxIt:\n",
    "        prob1 = train_predict(al, maxI, X_train, y_train, X_test)\n",
    "        print('1: ', score_c(prob1, y_test))\n",
    "        prob2 = train_predict2(al, maxI, X_train, y_train, X_test)\n",
    "        print('2: ', score_c(prob2, y_test))\n",
    "        prob4 = train_predict4(al, maxI, X_train, y_train, X_test)\n",
    "        print('4: ', score_c(prob4, y_test))\n",
    "        prob5 = train_predict5(al, maxI, X_train, y_train, X_test)\n",
    "        print('5: ', score_c(prob5, y_test))\n",
    "        probTotal = []\n",
    "        for i in range(len(prob1)):\n",
    "            eachClass = np.zeros(20)\n",
    "            # HardCoded ponderation\n",
    "            eachClass[prob1[i]] += 0.4\n",
    "            eachClass[prob2[i]] += 0.6\n",
    "            eachClass[prob4[i]] += 0.4\n",
    "            \n",
    "            \n",
    "            probTotal.append(np.argmax(eachClass))\n",
    "            \n",
    "        prob = score_c(probTotal, y_test)\n",
    "        print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toOutput = []\n",
    "for i in range(len(probTotal)):\n",
    "    toOutput.append({'Id': i, 'Category': classes_name[probTotal[i]]})\n",
    "convert_to_csv(toOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob8 = train_predict8(6, 3, X_train, y_train, X_test)\n",
    "print('1: ', score_c(prob8, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob7 = train_predict7(6, 3, X_train, y_train, X_test)\n",
    "print('1: ', score_c(prob7, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob6 = train_predict6(6, 3, X_train, y_train, X_test)\n",
    "print('1: ', score_c(prob6, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob9 = train_predict9(6, 3, X_train, y_train, X_test)\n",
    "print('1: ', score_c(prob9, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Compute confusion matrix\n",
    "array =  confusion_matrix(y_test, prob2_2)\n",
    "df_cm = pd.DataFrame(array, index = [i for i in classes_name],\n",
    "                  columns = [i for i in classes_name])\n",
    "plt.figure(figsize = (40,47))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
